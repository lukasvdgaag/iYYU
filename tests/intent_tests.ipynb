{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Intent recognition imports\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# ChatGPT imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from gpt import GPT\n",
    "from intent_model import IntentModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from JSON file\n",
    "with open(\"../intent_recognition.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "train_data = []\n",
    "for datum in data:\n",
    "    texts = datum[\"train_questions\"]\n",
    "    label = datum[\"intent\"]\n",
    "    for text in texts:\n",
    "        train_data.append((text, label))\n",
    "\n",
    "# Define the mapping between top-level labels and integers\n",
    "label_map = {label: i for i, label in enumerate(set([data[1] for data in train_data]))}\n",
    "\n",
    "# Convert the training data labels to integers using the label_map\n",
    "labels = torch.tensor([label_map[data[1]] for data in train_data])\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.0627923011779785\n",
      "Epoch 2, Loss: 4.076840400695801\n",
      "Epoch 3, Loss: 4.011010646820068\n",
      "Epoch 4, Loss: 3.991832971572876\n",
      "Epoch 5, Loss: 3.96270751953125\n",
      "Epoch 6, Loss: 3.976637125015259\n",
      "Epoch 7, Loss: 3.8393263816833496\n",
      "Epoch 8, Loss: 3.820101022720337\n",
      "Epoch 9, Loss: 3.8908259868621826\n",
      "Epoch 10, Loss: 3.456650495529175\n",
      "Epoch 11, Loss: 3.200932264328003\n",
      "Epoch 12, Loss: 2.9399046897888184\n",
      "Epoch 13, Loss: 2.7963833808898926\n",
      "Epoch 14, Loss: 2.3329925537109375\n",
      "Epoch 15, Loss: 2.121279001235962\n",
      "Epoch 16, Loss: 1.878674864768982\n",
      "Epoch 17, Loss: 1.6221086978912354\n",
      "Epoch 18, Loss: 1.3446102142333984\n",
      "Epoch 19, Loss: 1.153952956199646\n",
      "Epoch 20, Loss: 0.9768708944320679\n",
      "Epoch 21, Loss: 0.811667799949646\n",
      "Epoch 22, Loss: 0.6792150735855103\n",
      "Epoch 23, Loss: 0.5603086352348328\n",
      "Epoch 24, Loss: 0.4657444953918457\n",
      "Epoch 25, Loss: 0.38105008006095886\n"
     ]
    }
   ],
   "source": [
    "intent_model = IntentModel(train_data, label_map, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: platform_settings\n",
      "  Intent: location_password_change\n",
      "  Intent: reset_password_change\n",
      "  Intent: update_password_change\n",
      "  Intent: problem_update_password_change\n",
      "\n",
      "\n",
      "Category: My_visibility_settings\n",
      "  Intent: visibility_publish_profile_status\n",
      "  Intent: visibility_publish_profile_how_to\n",
      "\n",
      "\n",
      "Category: system notifications\n",
      "  Intent: change_system_critical_notification_setting\n",
      "  Intent: change_iYYU_news_notification_setting\n",
      "  Intent: change_update_notification_setting\n",
      "\n",
      "\n",
      "Category: connect\n",
      "  Intent: change_note_follower_notification_setting\n",
      "  Intent: change_connection_response_notification_setting\n",
      "  Intent: change_connection_request_notification_setting\n",
      "\n",
      "\n",
      "Category: interact\n",
      "  Intent: change_followed_user_note_notification_setting\n",
      "  Intent: change_message_notification_preference\n",
      "\n",
      "\n",
      "Category: generic\n",
      "  Intent: yes_response\n",
      "  Intent: no_response\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Your data is already a list of dictionaries\n",
    "categories = defaultdict(list)\n",
    "\n",
    "for item in data:\n",
    "    intent_text = item['intent']\n",
    "    if not item['use_gpt'] and not item['responses']:\n",
    "\n",
    "        intent_text += ' (Needs answers)'\n",
    "    categories[item['category']].append(intent_text)\n",
    "\n",
    "for category, intents in categories.items():\n",
    "    if(category == 'privacy_policy' or category ==  'legal_statement'):\n",
    "        continue\n",
    "\n",
    "    print(f'Category: {category}')\n",
    "    for intent in intents:\n",
    "        print(f'  Intent: {intent}')\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_file = \"./evaluation_results.json\"\n",
    "\n",
    "if os.path.isfile(evaluation_file):\n",
    "    with open(evaluation_file, \"r\") as file:\n",
    "        accuracies = json.load(file)\n",
    "else:\n",
    "    accuracies = intent_model.evaluate_model(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total correctness 86.58\n",
      "Intent: summarization_privacy\n",
      "Train question results: 5 out of 6 correct\n",
      "Total correctness for all questions: 83.33%\n",
      "\n",
      "\n",
      "Intent: third_parties\n",
      "Train question results: 0 out of 6 correct\n",
      "Total correctness for all questions: 0.0%\n",
      "\n",
      "\n",
      "Intent: personal_information\n",
      "Train question results: 3 out of 10 correct\n",
      "Total correctness for all questions: 30.0%\n",
      "\n",
      "\n",
      "Intent: personal_information_rights\n",
      "Train question results: 0 out of 10 correct\n",
      "Total correctness for all questions: 0.0%\n",
      "\n",
      "\n",
      "Intent: terms_of_service_legal_statement\n",
      "Train question results: 4 out of 10 correct\n",
      "Total correctness for all questions: 40.0%\n",
      "\n",
      "\n",
      "Intent: use_restrictions_legal_statement\n",
      "Train question results: 9 out of 10 correct\n",
      "Total correctness for all questions: 90.0%\n",
      "\n",
      "\n",
      "Intent: location_password_change\n",
      "Train question results: 1 out of 10 correct\n",
      "Total correctness for all questions: 10.0%\n",
      "\n",
      "\n",
      "Intent: reset_password_change\n",
      "Train question results: 3 out of 10 correct\n",
      "Total correctness for all questions: 30.0%\n",
      "\n",
      "\n",
      "Intent: update_password_change\n",
      "Train question results: 10 out of 13 correct\n",
      "Total correctness for all questions: 76.92%\n",
      "\n",
      "\n",
      "Intent: change_iYYU_news_notification_setting\n",
      "Train question results: 10 out of 10 correct\n",
      "Test question results: 4 out of 5 correct\n",
      "Advanced test question results: 5 out of 6 correct\n",
      "Total correctness for all questions: 90.48%\n",
      "\n",
      "\n",
      "Intent: change_connection_request_notification_setting\n",
      "Train question results: 3 out of 10 correct\n",
      "Test question results: 0 out of 5 correct\n",
      "Advanced test question results: 1 out of 6 correct\n",
      "Total correctness for all questions: 19.05%\n",
      "\n",
      "\n",
      "Intent: yes_response\n",
      "Train question results: 10 out of 10 correct\n",
      "Test question results: 1 out of 5 correct\n",
      "Advanced test question results: 1 out of 6 correct\n",
      "Total correctness for all questions: 57.14%\n",
      "\n",
      "\n",
      "Intent: no_response\n",
      "Train question results: 10 out of 10 correct\n",
      "Test question results: 0 out of 5 correct\n",
      "Advanced test question results: 0 out of 6 correct\n",
      "Total correctness for all questions: 47.62%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"total correctness\", accuracies[\"total_correctness\"])\n",
    "\n",
    "# \"total_correct_counts\": 608,\n",
    "# \"total_counts\": 663,\n",
    "\n",
    "for evaluation in accuracies[\"results\"]:\n",
    "    if (evaluation[\"total_correctness\"] == 100):\n",
    "        continue\n",
    "\n",
    "    print(f\"Intent: {evaluation['correct_intent']}\")\n",
    "    print(f\"Train question results: {evaluation['train_questions_results']}\")\n",
    "\n",
    "    test_results = evaluation.get('test_questions_results')\n",
    "    if test_results:\n",
    "        print(f\"Test question results: {test_results}\")\n",
    "        \n",
    "    advanced_results = evaluation.get('test_questions_advanced_results')\n",
    "    if advanced_results:\n",
    "        print(f\"Advanced test question results: {advanced_results}\")\n",
    "    \n",
    "    print(f\"Total correctness for all questions: {evaluation['total_correctness']}%\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
