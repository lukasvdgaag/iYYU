{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GPT-3.5 TURBO model prototype\n",
    "In dit notebook, zullen we testen of we met het GPT-3.5-turbo model van OpenAI proberen om een chatbot te maken voor iYYU. Deze zal uiteindelijk vragen moeten kunnen beantwoorden over de privacy en legal statements van iYYU, maar ook over de werking van de app en het instellen van de appinstellingen.\n",
    "\n",
    "We gebruiken publieke data van iYYU om de chatbot te trainen. Deze data is te vinden in de map `text`:\n",
    "- `legal.txt` bevat de legal statements van iYYU, afkomstig van de website van iYYU.\n",
    "- `privacy.txt` bevat de privacy statements van iYYU, afkomstig van de website van iYYU.\n",
    "- `account-settings.json` bevat een JSON-formatted lijst van gecategoriseerde account instellingen van iYYU, met alle opties, mogelijke waarden, de geadviseerde waarde en een korte beschrijving van de instelling."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:36:27.468953Z",
     "end_time": "2023-04-11T21:36:27.482478Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_newlines(serie):\n",
    "    serie = serie.str.replace('\\n', ' ')\n",
    "    serie = serie.str.replace('\\\\n', ' ')\n",
    "    serie = serie.str.replace('  ', ' ')\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bestanden inladen\n",
    "Hieronder laden we alle bestanden in die we nodig hebben om de chatbot te trainen. We gebruiken de `legal.txt` en `privacy.txt` bestanden om de chatbot te trainen op de legal en privacy statements van iYYU. We gebruiken het `account-settings.json` bestand om de chatbot te trainen op de account instellingen van iYYU. We gebruiken de `questions.txt` bestand om de chatbot te trainen op vragen die gebruikers kunnen stellen over de app en de account instellingen.\n",
    "\n",
    "Deze worden automatisch ingeladen vanuit de `text` map.\n",
    "\n",
    "We lezen hier alle bestanden uit en slaan ze op in een `.csv` bestand nadat ervoor hebben gezorgd dat alle linebreaks eruit zijn gehaald. Dit `.csv` bestand wordt opgeslagen in de `processed` map als `scraped.csv`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaagj\\AppData\\Local\\Temp\\ipykernel_85400\\2966875972.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  serie = serie.str.replace('\\\\n', ' ')\n"
     ]
    },
    {
     "data": {
      "text/plain": "                fname                                               text\n0           legal.txt  iYYU Terms & Conditions These Terms and Condit...\n1         privacy.txt  iYYU Privacy Policy This Privacy Policy sets o...\n2  training-data.json  {  \"visibility\": {   \"description\": \"By choosi...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>legal.txt</td>\n      <td>iYYU Terms &amp; Conditions These Terms and Condit...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>privacy.txt</td>\n      <td>iYYU Privacy Policy This Privacy Policy sets o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>training-data.json</td>\n      <td>{  \"visibility\": {   \"description\": \"By choosi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create a list to store the text files\n",
    "texts = []\n",
    "\n",
    "# Get all the text files in the text directory\n",
    "for file in os.listdir(\"text/\"):\n",
    "    # Open the file and read the text\n",
    "    with open(\"text/\" + file, \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "        texts.append((file, text))\n",
    "\n",
    "# Create a dataframe from the list of texts\n",
    "df = pd.DataFrame(texts, columns=['fname', 'text'])\n",
    "\n",
    "# Set the text column to be the raw text with the newlines removed\n",
    "df['text'] = remove_newlines(df.text)\n",
    "df.to_csv('processed/scraped.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:09:25.068444Z",
     "end_time": "2023-04-11T21:09:25.103721Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing\n",
    "\n",
    "We willen de data preprocessen zodat we deze kunnen gebruiken om de chatbot te trainen. Het is hiervoor nodig om de data te tokenizen. We gebruiken hiervoor de `tiktoken` library. Deze library is ontworpen om te werken met de GPT-3 modellen van OpenAI. We gebruiken de `cl100k_base` tokenizer die is ontworpen om te werken met de `ada-002` model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "                title                                               text  \\\n0           legal.txt  iYYU Terms & Conditions These Terms and Condit...   \n1         privacy.txt  iYYU Privacy Policy This Privacy Policy sets o...   \n2  training-data.json  {  \"visibility\": {   \"description\": \"By choosi...   \n\n   n_tokens  \n0      3131  \n1      2498  \n2       950  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>n_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>legal.txt</td>\n      <td>iYYU Terms &amp; Conditions These Terms and Condit...</td>\n      <td>3131</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>privacy.txt</td>\n      <td>iYYU Privacy Policy This Privacy Policy sets o...</td>\n      <td>2498</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>training-data.json</td>\n      <td>{  \"visibility\": {   \"description\": \"By choosi...</td>\n      <td>950</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# De cl100k_base tokenizer inladen, die is ontworpen om te werken met het ada-002 model.\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "df = pd.read_csv('processed/scraped.csv', index_col=0)\n",
    "df.columns = ['title', 'text']\n",
    "\n",
    "# Een nieuwe kolom genaamd 'n_tokens' toevoegen aan de dataframe, die de lengte van de tokenized text bevat.\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T22:07:00.548797Z",
     "end_time": "2023-04-11T22:07:00.582665Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chunking\n",
    "\n",
    "We willen de data chunken zodat het GPT-3.5-turbo model deze kan gebruiken. Er zit namelijk een limiet aan het aantal tokens dat het model in één keer kan verwerken.\n",
    "\n",
    "De code hieronder zal de tekst die we eerder hebben verwerkt naar het `scraped.csv` bestand in chunks van maximaal 500 tokens opsplitsen. We zullen dit doen door te splitsen om zinnen (.) en deze net zo lang toe voegen aan een chunk totdat deze de limiet van 500 tokens bereikt. We slaan deze chunks op in een nieuw .csv bestand genaamt `embeddings.csv`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "max_tokens = 500\n",
    "\n",
    "# Function to split the text into chunks of a maximum number of tokens\n",
    "def split_into_many(text, max_tokens=max_tokens):\n",
    "    # Split the text into sentences\n",
    "    sentences = text.split('. ')\n",
    "\n",
    "    # Get the number of tokens for each sentence\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "\n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "    # Loop through the sentences and tokens joined together in a tuple\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # If the number of tokens so far plus the number of tokens in the current sentence is greater\n",
    "        # than the max number of tokens, then add the chunk to the list of chunks and reset\n",
    "        # the chunk and tokens so far\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        # If the number of tokens in the current sentence is greater than the max number of\n",
    "        # tokens, go to the next sentence\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "\n",
    "    return chunks\n",
    "\n",
    "shortened = []\n",
    "\n",
    "# Loop through the dataframe\n",
    "for row in df.iterrows():\n",
    "\n",
    "    # If the text is None, go to the next row\n",
    "    if row[1]['text'] is None:\n",
    "        continue\n",
    "\n",
    "    # If the number of tokens is greater than the max number of tokens, split the text into chunks\n",
    "    if row[1]['n_tokens'] > max_tokens:\n",
    "        shortened += split_into_many(row[1]['text'])\n",
    "\n",
    "    # Otherwise, add the text to the list of shortened texts\n",
    "    else:\n",
    "        shortened.append(row[1]['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:09:25.117256Z",
     "end_time": "2023-04-11T21:09:25.189288Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  n_tokens\n0  iYYU Terms & Conditions These Terms and Condit...       480\n1  By accessing or using (any part of) the Platfo...       478\n2  You can become a Space Member by agreeing to t...       441\n3  To the maximum extent permitted by law, iYYU h...       452\n4  Are not or do not contain spam, are not machin...       492",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>n_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iYYU Terms &amp; Conditions These Terms and Condit...</td>\n      <td>480</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>By accessing or using (any part of) the Platfo...</td>\n      <td>478</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You can become a Space Member by agreeing to t...</td>\n      <td>441</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To the maximum extent permitted by law, iYYU h...</td>\n      <td>452</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Are not or do not contain spam, are not machin...</td>\n      <td>492</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(shortened, columns=['text'])\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T22:09:40.133377Z",
     "end_time": "2023-04-11T22:09:40.158771Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embeddings\n",
    "\n",
    "We zullen nu de embeddings van de chunks berekenen. Dit zijn vectors die de betekenis van de tekst weergeven. We zullen hiervoor het openai model `ada-002` gebruiken. Deze vectors worden bepaalt door de context van de tekst. Dit betekent dat de vector van een zin afhankelijk is van de zinnen die ervoor en erna komen. Dit maakt het mogelijk voor het model om relaties tussen woorden en zinnen te leren.\n",
    "De berekende embeddings zullen we toevoegen aan de dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  n_tokens  \\\n0  iYYU Terms & Conditions These Terms and Condit...       480   \n1  By accessing or using (any part of) the Platfo...       478   \n2  You can become a Space Member by agreeing to t...       441   \n3  To the maximum extent permitted by law, iYYU h...       452   \n4  Are not or do not contain spam, are not machin...       492   \n\n                                          embeddings  \n0  [-0.00584253529086709, -0.015280477702617645, ...  \n1  [0.015693487599492073, -0.01975192129611969, 0...  \n2  [0.005822580307722092, -0.028022408485412598, ...  \n3  [-0.001226945430971682, -0.013233720324933529,...  \n4  [-0.009652386419475079, -0.010911393910646439,...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>n_tokens</th>\n      <th>embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iYYU Terms &amp; Conditions These Terms and Condit...</td>\n      <td>480</td>\n      <td>[-0.00584253529086709, -0.015280477702617645, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>By accessing or using (any part of) the Platfo...</td>\n      <td>478</td>\n      <td>[0.015693487599492073, -0.01975192129611969, 0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You can become a Space Member by agreeing to t...</td>\n      <td>441</td>\n      <td>[0.005822580307722092, -0.028022408485412598, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To the maximum extent permitted by law, iYYU h...</td>\n      <td>452</td>\n      <td>[-0.001226945430971682, -0.013233720324933529,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Are not or do not contain spam, are not machin...</td>\n      <td>492</td>\n      <td>[-0.009652386419475079, -0.010911393910646439,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "# pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "df['embeddings'] = df.text.apply(lambda x: openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])\n",
    "df.to_csv('processed/embeddings.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:09:25.159818Z",
     "end_time": "2023-04-11T21:09:28.615463Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Context berekenen\n",
    "\n",
    "We zullen nu de context berekenen voor de input van de gebruiker. Dit doen we door de embeddings van de input te vergelijken met de embeddings van de chunks. We zullen de chunks sorteren op afstand van de input en deze toevoegen aan de context totdat de context de limiet van tokens is bereikt."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import distances_from_embeddings\n",
    "\n",
    "def create_context(\n",
    "        question, df, max_len=1800, size=\"ada\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the embeddings for the question\n",
    "    q_embeddings = openai.Embedding.create(input=question, engine='text-embedding-ada-002')['data'][0]['embedding']\n",
    "\n",
    "    # Get the distances from the embeddings\n",
    "    df['distances'] = distances_from_embeddings(q_embeddings, df['embeddings'].values, distance_metric='cosine')\n",
    "\n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "\n",
    "    # Sort by distance and add the text to the context until the context is too long\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "\n",
    "        # Add the length of the text to the current length\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "\n",
    "        # If the context is too long, break\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "\n",
    "        # Else add it to the text that is being returned\n",
    "        returns.append(row[\"text\"])\n",
    "\n",
    "    # Return the context\n",
    "    return \"\\n\\n###\\n\\n\".join(returns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:09:31.780409Z",
     "end_time": "2023-04-11T21:09:31.797528Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model aanroepen\n",
    "\n",
    "We zullen nu de functie `answer_question` aanroepen. Deze functie zal de context berekenen, afgeleid van de input van de gebruiker, en deze gebruiken om een antwoord te geven op de vraag van de gebruiker.\n",
    "\n",
    "We geven het model een start prompt mee om aan te geven wat de rol is van het model en hoe het antwoord moet geven. Het is hierbij ook belangrijk dat we het model goed afschermen, zodat het geen antwoord kan geven op onrelevante vragen die buiten de context vallen.\n",
    "\n",
    "Hiervoor gebruiken we `Prompt Engineering`. Dit is het proces waarbij we een prompt schrijven die een language model een specifieke taak laat uitvoeren. Dit gebeurd aan de hand van een lijst met instructies die het model moet volgen. Een goede prompt verhoogt de kwaliteit en accuraatheid van de output van het model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def answer_question(\n",
    "        df,\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        question=\"\",\n",
    "        max_len=1800,\n",
    "        size=\"ada\",\n",
    "        debug=False,\n",
    "        max_tokens=150,\n",
    "        stop_sequence=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = create_context(\n",
    "        question,\n",
    "        df,\n",
    "        max_len=max_len,\n",
    "        size=size,\n",
    "    )\n",
    "    # If debug, print the raw model response\n",
    "    if debug:\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        # Create a completions using the question and context\n",
    "        response = openai.ChatCompletion.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\",\n",
    "                 \"content\": f\"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"I don't know. You are the spokesperson of the company iYYU so you will refer to the company by its full name or 'we'. Context: {context}\"},\n",
    "                {\"role\": \"user\",\n",
    "                 \"content\": question},\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=stop_sequence,\n",
    "            model=model,\n",
    "        )\n",
    "        return response[\"choices\"][0]['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'iYYU is een platform dat gebruikers in staat stelt om in contact te blijven met anderen en berichten te verzenden en ontvangen. Het is eigendom van en wordt beheerd door iYYU B.V., gevestigd in Amsterdam, Nederland.'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(df, question=\"Wat is iYYU? Antwoord in het Nederlands.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:09:31.794941Z",
     "end_time": "2023-04-11T21:09:50.369642Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'This is a privacy policy for a website called iYYU. It tells you what information they collect from you when you use their website and how they use it. They promise to keep your information safe and not share it with anyone unless they have to. They also give you some rights, like the right to ask them to delete your information or to see what information they have about you. If you have any questions or concerns, you can contact them.'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(df, question=\"Could you give me a small summary of the privacy statement? Explain all the important points as if I were a 5 year old.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:09:50.371195Z",
     "end_time": "2023-04-11T21:10:14.554254Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
