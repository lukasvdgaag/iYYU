{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('ner_data.json', 'r') as f:\n",
    "    train_sentences = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 20/20 [02:14<00:00,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 134.7986, 'train_samples_per_second': 2.967, 'train_steps_per_second': 0.148, 'train_loss': 0.44267497062683103, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification, BertTokenizerFast, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define a mapping from label names to indices\n",
    "label_to_index = {\"O\": 0, \"setting_name\": 1, \"state\": 2}\n",
    "index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "\n",
    "# Function to encode the examples\n",
    "def encode_example(sentence):\n",
    "    inputs = tokenizer(sentence['text'], is_split_into_words=True, padding='max_length', truncation=True, max_length=128)\n",
    "    labels = [-100 if token_id==tokenizer.pad_token_id else label_to_index[label] for token_id, label in zip(inputs['input_ids'], sentence['ner'])]  \n",
    "    labels += [-100] * (128 - len(labels))  # pad labels to the max length\n",
    "    inputs['labels'] = labels\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# Encode all examples\n",
    "train_encodings = [encode_example(s) for s in train_sentences]\n",
    "train_encodings = [ {k: torch.tensor(v) for k, v in enc.items()} for enc in train_encodings]\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    # output_dir='./results',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    seed=42,  # for reproducibility\n",
    "    logging_steps=100,  # log loss every 100 steps\n",
    "    # logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_encodings,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Function to extract settings and states\n",
    "def extract_settings_and_states(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)\n",
    "\n",
    "    predicted_labels = [index_to_label[p] for p in predictions[0].tolist()]\n",
    "\n",
    "    # Match up the original tokens with their predicted labels\n",
    "    original_tokens = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    # Only include labels that are not 'O'\n",
    "    entities = [(token, label) for token, label in zip(original_tokens, predicted_labels) if label != 'O']\n",
    "\n",
    "    return entities\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted entities: [('publish', 'state'), ('profile', 'setting_name')]\n",
      "Predicted entities: [('di', 'state'), ('the', 'setting_name')]\n",
      "Predicted entities: [('search', 'setting_name')]\n",
      "Predicted entities: [('find', 'state'), ('##able', 'state'), ('logged', 'state'), ('in', 'state')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted entities:\", extract_settings_and_states(\"How can I publish my profile?\"))\n",
    "print(\"Predicted entities:\", extract_settings_and_states(\"How do I disable the connect with me setting?\"))\n",
    "print(\"Predicted entities:\", extract_settings_and_states(\"How do i make myself visible in the search?\"))\n",
    "print(\"Predicted entities:\", extract_settings_and_states(\"Can i make myself only findable to logged in users?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
