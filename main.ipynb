{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T18:35:32.171654700Z",
     "start_time": "2023-05-03T18:35:29.239897200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Can you summarize the privacy policy for me?', 'privacy_policy', 'summarization'), ('What information does the privacy policy collect?', 'privacy_policy', 'question_answering'), ('How can I opt out of data sharing?', 'privacy_policy', 'question_answering'), ('Is my personal information shared with third parties?', 'privacy_policy', 'question_answering'), ('What information does the privacy policy collect?', 'privacy_policy', 'collection'), ('How does the company use my personal information?', 'privacy_policy', 'usage'), ('Is my personal information shared with third parties?', 'privacy_policy', 'sharing'), ('How is my personal information stored and secured?', 'privacy_policy', 'storage_security'), ('What are my rights regarding my personal information?', 'privacy_policy', 'rights'), ('How can I request access to my personal information?', 'privacy_policy', 'access'), (\"Can I delete my personal information from the company's records?\", 'privacy_policy', 'deletion'), (\"What are the company's cookie policies?\", 'privacy_policy', 'cookie_policies'), ('Does the company comply with privacy regulations?', 'privacy_policy', 'compliance'), ('How often is the privacy policy updated?', 'privacy_policy', 'updates'), ('Can you summarize the privacy policy for me?', 'privacy_policy', 'summarization'), (\"What is the minimum age requirement for using the company's services?\", 'privacy_policy', 'age_requirement'), ('Can the company collect my geolocation data?', 'privacy_policy', 'geolocation'), ('What happens to my personal information if the company is acquired or merges with another company?', 'privacy_policy', 'mergers_acquisitions'), ('How does the company handle data breaches?', 'privacy_policy', 'data_breach'), ('Can I opt-out of targeted advertising?', 'privacy_policy', 'opt_out'), ('How can I contact the company for privacy-related concerns?', 'privacy_policy', 'contact'), ('What are the consequences of not agreeing to the privacy policy?', 'privacy_policy', 'consequences'), ('Does the company sell my personal information?', 'privacy_policy', 'selling'), ('What happens to my personal information when I terminate my account?', 'privacy_policy', 'account_termination'), ('What are the terms of service for this platform?', 'legal_statement', 'terms_of_service'), ('Can you summarize the liability section of the terms of service?', 'legal_statement', 'summarization'), ('What are the terms of service for this platform?', 'legal_statement', 'terms_of_service'), ('What is the governing law for the legal agreement?', 'legal_statement', 'governing_law'), ('Can you summarize the liability section of the legal agreement?', 'legal_statement', 'liability'), ('What is the dispute resolution process outlined in the legal agreement?', 'legal_statement', 'dispute_resolution'), ('Can I opt-out of arbitration?', 'legal_statement', 'arbitration'), ('How are disputes handled in small claims court?', 'legal_statement', 'small_claims_court'), ('What are my obligations as a user under the legal agreement?', 'legal_statement', 'user_obligations'), ('How does the legal agreement apply to intellectual property rights?', 'legal_statement', 'intellectual_property'), ('What are the restrictions on my use of the platform or service?', 'legal_statement', 'use_restrictions'), ('Can I transfer my account or subscription to someone else?', 'legal_statement', 'transfer'), ('What is the cancellation policy for subscriptions or services?', 'legal_statement', 'cancellation'), ('Are there any warranty disclaimers in the legal agreement?', 'legal_statement', 'warranty_disclaimers'), ('What are the limitations of liability in the legal agreement?', 'legal_statement', 'limitations_of_liability'), ('How does the legal agreement apply to third-party content or services?', 'legal_statement', 'third_party_content'), (\"What is the company's policy on refunds?\", 'legal_statement', 'refunds'), ('What happens if I violate the legal agreement?', 'legal_statement', 'violations'), ('where can i find the notifications centre', 'platform_settings', 'test_sentiment'), ('Where can I change my account password?', 'platform_settings', 'question_answering'), (\"I'd like to change my password?\", 'platform_settings', 'question_answering'), ('Is it possible to change my password?', 'platform_settings', 'question_answering'), ('Where can i change my password?', 'platform_settings', 'question_answering'), ('How do I reset my password?', 'platform_settings', 'question_answering'), ('I forgot my password, what do I do?', 'platform_settings', 'question_answering'), ('Can you help me change my password?', 'platform_settings', 'question_answering'), (\"Why can't I change my password?\", 'platform_settings', 'question_answering'), ('I need to update my password, how do I do that?', 'platform_settings', 'question_answering'), ('Can you explain the process for linking external accounts?', 'external_platform_settings', 'question_answering'), ('What data is shared with third-party platforms?', 'external_platform_settings', 'question_answering')]\n",
      "{'privacy_policy': ['summarization', 'question_answering', 'question_answering', 'question_answering', 'collection', 'usage', 'sharing', 'storage_security', 'rights', 'access', 'deletion', 'cookie_policies', 'compliance', 'updates', 'summarization', 'age_requirement', 'geolocation', 'mergers_acquisitions', 'data_breach', 'opt_out', 'contact', 'consequences', 'selling', 'account_termination'], 'legal_statement': ['terms_of_service', 'summarization', 'terms_of_service', 'governing_law', 'liability', 'dispute_resolution', 'arbitration', 'small_claims_court', 'user_obligations', 'intellectual_property', 'use_restrictions', 'transfer', 'cancellation', 'warranty_disclaimers', 'limitations_of_liability', 'third_party_content', 'refunds', 'violations'], 'platform_settings': ['test_sentiment', 'question_answering', 'question_answering', 'question_answering', 'question_answering', 'question_answering', 'question_answering', 'question_answering', 'question_answering', 'question_answering'], 'external_platform_settings': ['question_answering', 'question_answering']}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (54) to match target batch_size (1004).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 67\u001B[0m\n\u001B[0;32m     65\u001B[0m top_level_outputs, sub_level_outputs \u001B[38;5;241m=\u001B[39m model(inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m], attention_mask\u001B[38;5;241m=\u001B[39minputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     66\u001B[0m top_level_loss \u001B[38;5;241m=\u001B[39m loss_fn(top_level_outputs, top_level_labels)\n\u001B[1;32m---> 67\u001B[0m sub_level_loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43msub_level_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_level_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     69\u001B[0m loss \u001B[38;5;241m=\u001B[39m top_level_loss \u001B[38;5;241m+\u001B[39m sub_level_loss\n\u001B[0;32m     70\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m   1173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m-> 1174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1175\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1176\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001B[0m, in \u001B[0;36mcross_entropy\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[0;32m   3027\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3028\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 3029\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: Expected input batch_size (54) to match target batch_size (1004)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "\n",
    "class IntentAndSentimentDataset(Dataset):\n",
    "    def __init__(self, tokenizer, texts, top_level_labels, sub_level_labels):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.top_level_labels = top_level_labels\n",
    "        self.sub_level_labels = sub_level_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer.encode_plus(self.texts[idx], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        item = {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
    "            \"top_level_label\": self.top_level_labels[idx],\n",
    "            \"sub_level_label\": self.sub_level_labels[idx]\n",
    "        }\n",
    "        return item\n",
    "\n",
    "# Load the data from JSON file\n",
    "with open(\"sentiment_analysis.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Define the training data\n",
    "train_data = []\n",
    "sub_labels = {}\n",
    "for top_level_label, sub_level_labels in data.items():\n",
    "    for sub_level_label_data in sub_level_labels:\n",
    "        text = sub_level_label_data[\"text\"]\n",
    "        sub_level_label = sub_level_label_data[\"sub_level_label\"]\n",
    "        train_data.append((text, top_level_label, sub_level_label))\n",
    "        if top_level_label not in sub_labels:\n",
    "            sub_labels[top_level_label] = []\n",
    "        sub_labels[top_level_label].append(sub_level_label)\n",
    "\n",
    "# Define the mapping between top-level labels and integers\n",
    "top_level_label_map = {label: i for i, label in enumerate(set([data[1] for data in train_data]))}\n",
    "\n",
    "# Define the mapping between sub-level labels and integers\n",
    "sub_level_label_map = {sub_label: i for i, sub_label in enumerate(set([sub_label for sub_labels_list in sub_labels.values() for sub_label in sub_labels_list]))}\n",
    "\n",
    "# Convert the training data labels to integers using the label_map and sub_label_map\n",
    "# A tensor is a multi-dimensional array that looks like a numpy array, it's used for neural networks\n",
    "top_level_labels = torch.tensor([top_level_label_map[data[1]] for data in train_data])\n",
    "sub_level_labels = torch.tensor([sub_level_label_map[sub_label] for data in train_data for sub_label in sub_labels[data[1]]])\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "base_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model = CustomBertForIntentAndSentimentClassification(base_model, num_top_labels=len(top_level_label_map), num_sub_labels=len(sub_level_label_map))\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the training data and convert to tensors\n",
    "inputs = tokenizer.batch_encode_plus([data[0] for data in train_data], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Fine-tune the model on the training data\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "print(train_data)\n",
    "print(sub_labels)\n",
    "\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    top_level_outputs, sub_level_outputs = model(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "    top_level_loss = loss_fn(top_level_outputs, top_level_labels)\n",
    "    sub_level_loss = loss_fn(sub_level_outputs, sub_level_labels)\n",
    "\n",
    "    loss = top_level_loss + sub_level_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis query function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T16:15:18.822968600Z",
     "start_time": "2023-05-03T16:15:18.725137100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top level: 0\n",
      "{'platform_settings': 0, 'external_platform_settings': 1, 'privacy_policy': 2, 'legal_statement': 3}\n",
      "sub level: 0\n",
      "{'cancellation': 0, 'arbitration': 1, 'test_sentiment': 2, 'terms_of_service': 3, 'liability': 4, 'governing_law': 5, 'refunds': 6, 'contact': 7, 'small_claims_court': 8, 'mergers_acquisitions': 9, 'third_party_content': 10, 'transfer': 11, 'limitations_of_liability': 12, 'selling': 13, 'access': 14, 'compliance': 15, 'violations': 16, 'storage_security': 17, 'sharing': 18, 'usage': 19, 'question_answering': 20, 'cookie_policies': 21, 'data_breach': 22, 'collection': 23, 'dispute_resolution': 24, 'use_restrictions': 25, 'intellectual_property': 26, 'account_termination': 27, 'summarization': 28, 'user_obligations': 29, 'geolocation': 30, 'consequences': 31, 'deletion': 32, 'warranty_disclaimers': 33, 'opt_out': 34, 'rights': 35, 'age_requirement': 36, 'updates': 37}\n",
      "platform_settings cancellation\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "\n",
    "def predict_intent(text):\n",
    "    inputs = tokenizer.encode_plus(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    top_level_outputs, sub_level_outputs = model(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "    top_level_predicted_label = torch.argmax(top_level_outputs).item()\n",
    "    sub_level_predicted_label = torch.argmax(sub_level_outputs).item()\n",
    "\n",
    "    top_level_predicted_intent = [k for k, v in top_level_label_map.items() if v == top_level_predicted_label]\n",
    "    sub_level_predicted_intent = [k for k, v in sub_level_label_map.items() if v == sub_level_predicted_label]\n",
    "\n",
    "    return top_level_predicted_intent[0] if top_level_predicted_intent else None, sub_level_predicted_intent[0] if sub_level_predicted_intent else None\n",
    "\n",
    "\n",
    "\n",
    "top_level_intents, sub_level_intents = predict_intent(\"How do I reset my password?\")\n",
    "print(top_level_intents, sub_level_intents)\n",
    "# top_level_intents, sub_level_intents = predict_intent(\"Can you summarize the liability section of the terms of service?\")\n",
    "# print(top_level_intents, sub_level_intents)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# GPT model herel \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gpt import GPT\n",
    "\n",
    "gpt_model = GPT()\n",
    "\n",
    "#gpt_model.answer_question(question='What is the most important thing I need to know about your privacy statement?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT query function here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "import random\n",
    "\n",
    "# load the pre-trained intent analysis model\n",
    "# nlp = spacy.load(\"en_trf_bertbaseuncased_lg\")\n",
    "\n",
    "response_map = {\n",
    "    (\"security\", \"security_relating_to\"): [\"Our security measures include...\", \"We take security very seriously and have implemented...\"],\n",
    "    (\"security\", \"security_concerns\"): [\"We understand your security concerns and have taken steps to address them.\", \"You can trust that your information is safe with us.\"],\n",
    "    (\"information\", \"information_about\"): [\"Our store offers a variety of products, including...\", \"We also have a rewards program that allows you to earn points on your purchases.\"],\n",
    "    (\"information\", \"information_schedule\"): [\"We are open from 9am to 10pm, 7 days a week.\", \"Our business hours are 9am to 5pm, Monday to Friday.\"],\n",
    "    (\"help\", \"help_with_finding\"): [\"Here are some hotels near the airport:...\", \"I can help you find a hotel that meets your needs.\"],\n",
    "    (\"help\", \"help_with_booking\"): [\"You can book a room on our website or by calling our reservation hotline.\", \"We also offer a loyalty program that gives you discounts on future bookings.\"],\n",
    "    (\"information\", \"ordering\"): [\"You can place an order on our website or by calling our order hotline.\", \"We also offer a loyalty program that gives you discounts on future orders.\"]\n",
    "}\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def user(user_message, history):\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history):\n",
    "        user_message = history[-1][0]\n",
    "\n",
    "        intent = predict_intent(text=user_message)\n",
    "        print('intent:', intent)\n",
    "        # Random choice randomly chooses one of the options that matches the intent\n",
    "     \n",
    "        # generating a response with GPT if the main intent was 'privacy_policy' or 'legal_statement'\n",
    "        use_gpt = intent[0] == 'privacy_policy' or intent[0] == 'legal_statement'\n",
    "\n",
    "        response = gpt_model.answer_question(question=user_message) if use_gpt else 'No idea, bitch'\n",
    "\n",
    "        # response = random.choice(response_map[intent])\n",
    "        history[-1][1] = response\n",
    "        # The sleep is to simulate a more natural conversation\n",
    "        time.sleep(1)\n",
    "        return history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
