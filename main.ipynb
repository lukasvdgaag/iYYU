{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Intent recognition imports\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# ChatGPT imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from gpt import GPT\n",
    "from settings import Settings\n",
    "from intent_model import IntentModel\n",
    "\n",
    "# Chat demo\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 21:02:38.484748: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "random.seed(SEED)\n",
    "# numpy.random.seed(SEED)\n",
    "from transformers import set_seed\n",
    "set_seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from JSON file\n",
    "with open(\"intent_recognition_v2.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "validation_data = []\n",
    "train_data = []\n",
    "for datum in data:\n",
    "    texts = datum[\"train_questions\"]\n",
    "    label = datum[\"intent\"]\n",
    "    validation = datum[\"test_questions\"]\n",
    "    for text in texts:\n",
    "        train_data.append((text, label))\n",
    "    for text in validation:\n",
    "        validation_data.append((text, label))\n",
    "\n",
    "# Concatenate train and validation data for generating label_map\n",
    "all_data = train_data + validation_data\n",
    "\n",
    "# Define the mapping between top-level labels and integers\n",
    "# Sort the labels before enumerating\n",
    "label_map = {label: i for i, label in enumerate(sorted(set([data[1] for data in all_data])))}\n",
    "\n",
    "# Convert the training data labels to integers using the label_map\n",
    "train_labels = torch.tensor([label_map[data[1]] for data in train_data])\n",
    "validation_labels = torch.tensor([label_map[data[1]] for data in validation_data])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_model = IntentModel(train_data, validation_data, label_map, train_labels, validation_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intent_model = IntentModel(train_data, validation_data, train_label_map, train_labels, validation_labels).test_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(intent_model.get_intent(\"Can you provide details on the rules pertaining to the age limit for using the company's services?\")[0], \": minimum age\")\n",
    "print(intent_model.get_intent(\"Could you summarize the main provisions of the legal statement?\")[0], \": legal_statement_information\")\n",
    "print(intent_model.get_intent(\"Are you allowed to transfer ownership of my account or subscription to another individual?\")[0], \": transfer_legal_statement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest confidence intent: minimum_age\n",
      "Highest confidence score: [0.0021063138265162706, 0.008230205625295639, 0.004287931136786938, 0.004593479447066784, 0.0021339794620871544, 0.0032130868639796972, 0.0011811940930783749, 0.0017529346514493227, 0.004205392207950354, 0.0009162149508483708, 0.0004708093765657395, 0.9341235756874084, 0.00236311717890203, 0.00752151058986783, 0.001552237314172089, 0.0017632232047617435, 0.004246020223945379, 0.0003761829575523734, 0.0008844478870742023, 0.0011943138670176268, 0.012883775867521763]\n",
      "21\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'IntentModel' object has no attribute 'train_label_map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mHighest confidence score:\u001b[39m\u001b[39m\"\u001b[39m, confidence_scores)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(confidence_scores))\n\u001b[0;32m---> 12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(intent_model\u001b[39m.\u001b[39;49mtrain_label_map\u001b[39m.\u001b[39mkeys()))\n\u001b[1;32m     14\u001b[0m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[1;32m     15\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mkeys\u001b[39m\u001b[39m'\u001b[39m: intent_model\u001b[39m.\u001b[39mtrain_label_map\u001b[39m.\u001b[39mkeys(),\n\u001b[1;32m     16\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mconfidences\u001b[39m\u001b[39m'\u001b[39m: confidence_scores\n\u001b[1;32m     17\u001b[0m })\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'IntentModel' object has no attribute 'train_label_map'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# test the intent model\n",
    "predicted_intent, confidence_scores = intent_model.get_intent(\"Can you provide details on the rules pertaining to the age limit for using the company's services?\")\n",
    "\n",
    "# Retrieve the intent label and its corresponding confidence score\n",
    "highest_confidence_intent = predicted_intent\n",
    "\n",
    "print(\"Highest confidence intent:\", highest_confidence_intent)\n",
    "print(\"Highest confidence score:\", confidence_scores)\n",
    "print(len(confidence_scores))\n",
    "print(len(intent_model.train_label_map.keys()))\n",
    "\n",
    "pd.DataFrame({\n",
    "    'keys': intent_model.train_label_map.keys(),\n",
    "    'confidences': confidence_scores\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT model here\n",
    "gpt_model = GPT()\n",
    "\n",
    "# gpt_model = False\n",
    "\n",
    "# Test ChatGPT model\n",
    "# gpt_model.answer_question(question='What is the most important thing I need to know about your privacy statement?')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Settings class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_model = Settings()\n",
    "\n",
    "# Test the settings model\n",
    "# settings_model.update_user_setting(\"1\", \"profile_published\", False)\n",
    "settings_model.set_user_calling_card_visibility(user_id = \"0\", individual_user_id = \"2\", profile_card_component = \"profile_card_component_3_visible\", component_state = True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get response using intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_by_intent(intent):\n",
    "    for object in data:\n",
    "        if object['intent'] == intent:\n",
    "            return object\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up gradio chat for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme = gr.themes.Soft(\n",
    "    primary_hue=\"orange\",\n",
    "    secondary_hue=\"orange\",\n",
    ").set(\n",
    "    body_text_color_dark='*neutral_800',\n",
    "    background_fill_primary_dark='*neutral_50',\n",
    "    background_fill_secondary_dark='*neutral_50',\n",
    "    border_color_accent_dark='*primary_300',\n",
    "    border_color_primary_dark='*neutral_200',\n",
    "    color_accent_soft_dark='*primary_50',\n",
    "    link_text_color_dark='*secondary_600',\n",
    "    link_text_color_active_dark='*secondary_600',\n",
    "    link_text_color_hover_dark='*secondary_700',\n",
    "    link_text_color_visited_dark='*secondary_500',\n",
    "    block_background_fill='*neutral_100',\n",
    "    block_background_fill_dark='*neutral_100',\n",
    "    block_label_background_fill='*primary_400',\n",
    "    block_label_background_fill_dark='*primary_400',\n",
    "    block_label_text_color='*neutral_50',\n",
    "    block_label_text_color_dark='*neutral_50',\n",
    "    block_title_text_color='*neutral_50',\n",
    "    block_title_text_color_dark='*neutral_50',\n",
    "    checkbox_background_color_dark='*background_fill_primary',\n",
    "    checkbox_background_color_selected='*primary_500',\n",
    "    checkbox_background_color_selected_dark='*primary_500',\n",
    "    checkbox_border_color_dark='*neutral_100',\n",
    "    checkbox_border_color_focus='*primary_300',\n",
    "    checkbox_border_color_focus_dark='*primary_300',\n",
    "    checkbox_border_color_hover_dark='*neutral_300',\n",
    "    checkbox_border_color_selected='*primary_500',\n",
    "    checkbox_border_color_selected_dark='*primary_500',\n",
    "    checkbox_border_width_dark='1px',\n",
    "    checkbox_label_background_fill_selected_dark='*primary_500',\n",
    "    checkbox_label_text_color_selected_dark='white',\n",
    "    error_background_fill_dark='#fee2e2',\n",
    "    error_border_color_dark='#fecaca',\n",
    "    input_background_fill_dark='white',\n",
    "    input_background_fill_focus_dark='*secondary_500',\n",
    "    input_border_color_dark='*neutral_50',\n",
    "    input_border_color_focus_dark='*secondary_300',\n",
    "    input_placeholder_color_dark='*neutral_400',\n",
    "    slider_color_dark='*primary_500',\n",
    "    stat_background_fill_dark='*primary_300',\n",
    "    table_border_color_dark='*neutral_300',\n",
    "    table_even_background_fill_dark='white',\n",
    "    table_odd_background_fill_dark='*neutral_50',\n",
    "    button_primary_background_fill_dark='*primary_500',\n",
    "    button_primary_background_fill_hover_dark='*primary_400',\n",
    "    button_primary_border_color_dark='*primary_200',\n",
    "    button_secondary_background_fill_dark='white',\n",
    "    button_secondary_background_fill_hover_dark='*neutral_100',\n",
    "    button_secondary_border_color_dark='*neutral_200',\n",
    "    button_secondary_text_color_dark='*neutral_800'\n",
    ")\n",
    "\n",
    "with gr.Blocks(theme=theme, css=\"chat/chat.css\") as demo:\n",
    "    gr.Image(\"https://iyyu.com/_nuxt/img/navbar_logoW@2x.79eba99.png\", interactive=False,\n",
    "             tool=\"image\", show_label=False, elem_classes=\"logo\").style(width=200)\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    submit = gr.Button(\"Submit\")\n",
    "\n",
    "    def user(user_message, history):\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history):\n",
    "        user_message = history[-1][0]\n",
    "\n",
    "        intent, confidence_score = intent_model.get_intent(question=user_message)\n",
    "        print('intent:', intent)\n",
    "        print('confidence:', confidence_score)\n",
    "\n",
    "        confidence_score = max(confidence_score)\n",
    "\n",
    "        intent = get_object_by_intent(intent)\n",
    "\n",
    "\n",
    "        # generating a response with GPT if the main intent was 'privacy_policy' or 'legal_statement'\n",
    "        use_gpt = intent['use_gpt']\n",
    "        generate_context = True\n",
    "\n",
    "        # if the intent is 'privacy_policy' or 'legal_statement', use GPT to generate a response\n",
    "        response = ('(ChatGPT - intent found: {}): \\n{}'.format(intent['intent'], gpt_model.answer_question(question=user_message))\n",
    "                    if use_gpt else\n",
    "                    '<em><strong>(intent found ({}): {}):</strong></em> \\n{}'.format(confidence_score, intent['intent'], intent['responses'][0]))\n",
    "        # response = '(ChatGPT - intent found: {}): \\n{}'.format(intent['intent'], gpt_model.answer_question(question=user_message)) if use_gpt else '(intent found: {}): \\n{}'.format(intent['intent'], intent['responses'][0])\n",
    "\n",
    "        # response = random.choice(response_map[intent])\n",
    "        history[-1][1] = response\n",
    "        # The sleep is to simulate a more natural conversation\n",
    "        if not use_gpt:\n",
    "            time.sleep(1)\n",
    "        return history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    submit.click(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
