{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Intent recognition imports\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# ChatGPT imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from gpt import GPT\n",
    "from settings import Settings\n",
    "from intent_model import IntentModel\n",
    "\n",
    "# Chat demo\n",
    "import gradio as gr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from JSON file\n",
    "with open(\"intent_recognition.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "train_data = []\n",
    "for datum in data:\n",
    "    texts = datum[\"train_questions\"]\n",
    "    label = datum[\"intent\"]\n",
    "    for text in texts:\n",
    "        train_data.append((text, label))\n",
    "\n",
    "# Define the mapping between top-level labels and integers\n",
    "label_map = {label: i for i, label in enumerate(set([data[1] for data in train_data]))}\n",
    "\n",
    "# Convert the training data labels to integers using the label_map\n",
    "labels = torch.tensor([label_map[data[1]] for data in train_data])\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_model = IntentModel(train_data, label_map, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\school\\iYYU\\gpt.py:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  serie = serie.str.replace('\\\\n', ' ')\n"
     ]
    }
   ],
   "source": [
    "# GPT model here\n",
    "gpt_model = GPT()\n",
    "\n",
    "# gpt_model = False\n",
    "\n",
    "# Test ChatGPT model\n",
    "# gpt_model.answer_question(question='What is the most important thing I need to know about your privacy statement?')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Settings class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings_model = Settings()\n",
    "\n",
    "# user_id = input(\"Enter the ID of the existing user from the JSON file: \")\n",
    "# settings_model.set_current_user(user_id)\n",
    "# security_level = settings_model.estimate_user_security_level()\n",
    "# print(\"User security level:\", security_level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get response using intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_by_intent(intent):\n",
    "    for object in data:\n",
    "        if object['intent'] == intent:\n",
    "            return object\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up gradio chat for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent: contact_privacy_concerns\n",
      "intent: cookie_policy\n",
      "intent: personal_information_third_parties\n",
      "The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 62e356e2b8f34a48373bb3efd55ecc02 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 62e356e2b8f34a48373bb3efd55ecc02 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 62e356e2b8f34a48373bb3efd55ecc02 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 09:59:58 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '121', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '2', 'x-ratelimit-remaining-tokens': '38320', 'x-ratelimit-reset-requests': '20s', 'x-ratelimit-reset-tokens': '2.52s', 'x-request-id': '62e356e2b8f34a48373bb3efd55ecc02', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbc72fa69ad0ea9-AMS', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    }
   ],
   "source": [
    "theme = gr.themes.Soft(\n",
    "    primary_hue=\"orange\",\n",
    "    secondary_hue=\"orange\",\n",
    ").set(\n",
    "    body_text_color_dark='*neutral_800',\n",
    "    background_fill_primary_dark='*neutral_50',\n",
    "    background_fill_secondary_dark='*neutral_50',\n",
    "    border_color_accent_dark='*primary_300',\n",
    "    border_color_primary_dark='*neutral_200',\n",
    "    color_accent_soft_dark='*primary_50',\n",
    "    link_text_color_dark='*secondary_600',\n",
    "    link_text_color_active_dark='*secondary_600',\n",
    "    link_text_color_hover_dark='*secondary_700',\n",
    "    link_text_color_visited_dark='*secondary_500',\n",
    "    block_background_fill='*neutral_100',\n",
    "    block_background_fill_dark='*neutral_100',\n",
    "    block_label_background_fill='*primary_400',\n",
    "    block_label_background_fill_dark='*primary_400',\n",
    "    block_label_text_color='*neutral_50',\n",
    "    block_label_text_color_dark='*neutral_50',\n",
    "    block_title_text_color='*neutral_50',\n",
    "    block_title_text_color_dark='*neutral_50',\n",
    "    checkbox_background_color_dark='*background_fill_primary',\n",
    "    checkbox_background_color_selected='*primary_500',\n",
    "    checkbox_background_color_selected_dark='*primary_500',\n",
    "    checkbox_border_color_dark='*neutral_100',\n",
    "    checkbox_border_color_focus='*primary_300',\n",
    "    checkbox_border_color_focus_dark='*primary_300',\n",
    "    checkbox_border_color_hover_dark='*neutral_300',\n",
    "    checkbox_border_color_selected='*primary_500',\n",
    "    checkbox_border_color_selected_dark='*primary_500',\n",
    "    checkbox_border_width_dark='1px',\n",
    "    checkbox_label_background_fill_selected_dark='*primary_500',\n",
    "    checkbox_label_text_color_selected_dark='white',\n",
    "    error_background_fill_dark='#fee2e2',\n",
    "    error_border_color_dark='#fecaca',\n",
    "    input_background_fill_dark='white',\n",
    "    input_background_fill_focus_dark='*secondary_500',\n",
    "    input_border_color_dark='*neutral_50',\n",
    "    input_border_color_focus_dark='*secondary_300',\n",
    "    input_placeholder_color_dark='*neutral_400',\n",
    "    slider_color_dark='*primary_500',\n",
    "    stat_background_fill_dark='*primary_300',\n",
    "    table_border_color_dark='*neutral_300',\n",
    "    table_even_background_fill_dark='white',\n",
    "    table_odd_background_fill_dark='*neutral_50',\n",
    "    button_primary_background_fill_dark='*primary_500',\n",
    "    button_primary_background_fill_hover_dark='*primary_400',\n",
    "    button_primary_border_color_dark='*primary_200',\n",
    "    button_secondary_background_fill_dark='white',\n",
    "    button_secondary_background_fill_hover_dark='*neutral_100',\n",
    "    button_secondary_border_color_dark='*neutral_200',\n",
    "    button_secondary_text_color_dark='*neutral_800'\n",
    ")\n",
    "\n",
    "with gr.Blocks(theme=theme, css=\"chat/chat.css\") as demo:\n",
    "    gr.Image(\"https://iyyu.com/_nuxt/img/navbar_logoW@2x.79eba99.png\", interactive=False,\n",
    "             tool=\"image\", show_label=False, elem_classes=\"logo\").style(width=200)\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    submit = gr.Button(\"Submit\")\n",
    "\n",
    "    def user(user_message, history):\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history):\n",
    "        user_message = history[-1][0]\n",
    "\n",
    "        intent = intent_model.get_intent(question=user_message)\n",
    "        print('intent:', intent)\n",
    "\n",
    "        intent = get_object_by_intent(intent)\n",
    "\n",
    "        # generating a response with GPT if the main intent was 'privacy_policy' or 'legal_statement'\n",
    "        use_gpt = intent['use_gpt']\n",
    "\n",
    "        # if the intent is 'privacy_policy' or 'legal_statement', use GPT to generate a response\n",
    "        response = ('(ChatGPT - intent found: {}): \\n{}'.format(intent['intent'], gpt_model.answer_question(question=user_message))\n",
    "                    if use_gpt else\n",
    "                    '(intent found: {}): \\n{}'.format(intent['intent'], intent['responses'][0]))\n",
    "        # response = '(ChatGPT - intent found: {}): \\n{}'.format(intent['intent'], gpt_model.answer_question(question=user_message)) if use_gpt else '(intent found: {}): \\n{}'.format(intent['intent'], intent['responses'][0])\n",
    "\n",
    "        # response = random.choice(response_map[intent])\n",
    "        history[-1][1] = response\n",
    "        # The sleep is to simulate a more natural conversation\n",
    "        if not use_gpt:\n",
    "            time.sleep(1)\n",
    "        return history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    submit.click(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
